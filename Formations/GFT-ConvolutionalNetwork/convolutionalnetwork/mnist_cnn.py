# -*- coding: utf-8 -*-
"""MNIST CNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QXrCzBXuLha9ThMr16epxsIeASXNA7zs

The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning.
"""

#Install TensorFlow
import tensorflow as tf

#Import matplotlib for plotting
import matplotlib.pyplot as plt

"""Load the MNIST dataset"""

#Load MNIST Dataset

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()

"""Review some dataset values"""

#Print some images and its labels
num = 10
num_row = 2
num_col = 5

images = x_train[:num]
labels = y_train[:num]
# plot images
fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))
for i in range(num):
    ax = axes[i//num_col, i%num_col]
    ax.imshow(images[i], cmap='gray')
    ax.set_title('Label: {}'.format(labels[i]))
plt.tight_layout()
plt.show()

"""Shape of the images:"""

x_train.shape

"""Prepare the data"""

#Normalize values between 0 and 1
x_train, x_test = x_train / 255.0, x_test / 255.0
x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)
x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)

"""Build a Sequential NN with Convoluted layers"""

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),
  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])

import os
directory = './generated/'
try:
    os.makedirs(directory)
except:
    print("Directory already exists: [" + directory + "]")
tf.keras.utils.plot_model(model, to_file=f"{directory}model_cnn.png", show_shapes=True)

"""For each example the model returns a vector of "logits" or "log-odds" scores, one for each class."""

predictions = model(x_train[:1]).numpy()
predictions

loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

loss_fn(y_train[:1], predictions).numpy()

model.compile(optimizer='adam',
              loss=loss_fn,
              metrics=['accuracy'])

model.summary()

history = model.fit(x_train, y_train, epochs=5, validation_split=0.1)

"""The fit method returns a history object that we can use to understand how the training performed."""

def display_training_curves(training, validation, title, subplot):
  ax = plt.subplot(subplot)
  ax.plot(training)
  ax.plot(validation)
  ax.set_title('model '+ title)
  ax.set_ylabel(title)
  ax.set_xlabel('epoch')
  ax.legend(['training', 'validation'])

plt.subplots(figsize=(10,10))
plt.tight_layout()
display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)
display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)
plt.show()

model.evaluate(x_test,  y_test, verbose=2)

probability_model = tf.keras.Sequential([
  model,
  tf.keras.layers.Softmax()
])

#Some imports to pretty print things
import numpy as np
import pandas as pd
import seaborn as sn

#Probabilitys
np.set_printoptions(formatter={'float': '{: 0.4f}'.format})
probability_model(x_test[:5])

data = {'y_Actual':    y_test,
        'y_Predicted': np.argmax(probability_model(x_test), axis=1)} 
df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])

confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])

sn.heatmap(confusion_matrix, annot=True, fmt="d")
plt.show()