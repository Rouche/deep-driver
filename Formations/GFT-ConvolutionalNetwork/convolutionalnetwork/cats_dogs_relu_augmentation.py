# -*- coding: utf-8 -*-
"""Cats&Dogs- Relu - Augmentation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W2u_NWWSvHu1eqFga6zqAFXk4P5Jgrkj
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import os

"""# Downloading data
Use TensorFlow Datasets to load the cats and dogs dataset.

This tfds package is the easiest way to load pre-defined data.
"""

import tensorflow_datasets as tfds

"""The tfds.load method downloads and caches the data, and returns a tf.data.Dataset object. These objects provide powerful, efficient methods for manipulating data and piping it into your model.

Since "cats_vs_dogs" doesn't define standard splits, use the subsplit feature to divide it into (train, validation, test) with 80%, 10%, and 10% of the data respectively.
"""

(raw_train, raw_validation, raw_test), metadata = tfds.load(
    'cats_vs_dogs',
    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],
    with_info=True,
    as_supervised=True,
)

"""The resulting tf.data.Dataset objects contain (image, label) pairs where the images have variable shape and 3 channels, and the label is a scalar."""

print(raw_train)
print(raw_validation)
print(raw_test)

"""Show the first two images and labels from the training set:"""

get_label_name = metadata.features['label'].int2str

for image, label in raw_train.take(2):
  plt.figure()
  plt.imshow(image)
  plt.title(get_label_name(label))
plt.show()

"""Format the Data
Use the tf.image module to format the images for the task.

Resize the images to a fixed input size, and rescale the input channels to a range of [-1,1]
"""

IMG_SIZE = 160 # All images will be resized to 160x160

def augment(image,label):
  #image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]
  image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE+6, IMG_SIZE+6) # Add 6 pixels of padding
  image = tf.image.random_crop(image, size=[IMG_SIZE, IMG_SIZE, 3]) # Random crop back to 28x28
  image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness
  image = tf.image.random_flip_left_right(image)
  image = tf.image.random_flip_up_down(image)


  return image,label

def format_example(image, label):
  image = tf.cast(image, tf.float32)
  image = (image/127.5) - 1
  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
  return image, label

"""Apply this function to each item in the dataset using the map method:"""

train = raw_train.map(format_example)
validation = raw_validation.map(format_example)
test = raw_test.map(format_example)

"""Now shuffle and batch the data."""

BATCH_SIZE = 32
SHUFFLE_BUFFER_SIZE = 2000

train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)
validation_batches = validation.batch(BATCH_SIZE)
test_batches = test.batch(BATCH_SIZE)

"""Inspect a batch of data:"""

for image_batch, label_batch in train_batches.take(1):
   pass

image_batch.shape

"""# Create the CNN model

Create a CNN traditional model
"""

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(60, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),
  tf.keras.layers.Conv2D(60, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Conv2D(60, (3,3), activation='relu'),
  tf.keras.layers.Conv2D(60, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Conv2D(120, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
  tf.keras.layers.Conv2D(120, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Conv2D(240, (3,3), activation='relu'),
  tf.keras.layers.GlobalAveragePooling2D(),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(1)
])

"""#Â Compile the model
You must compile the model before training it. Since there are two classes, use a binary cross-entropy loss with from_logits=True since the model provides a linear output.
"""

base_learning_rate = 0.0001

model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.summary()

len(model.trainable_variables)

"""# Train the model
After training for 5 epochs, you should see ~80% accuracy.
"""

initial_epochs = 5
validation_steps=20

loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)

print("initial loss: {:.2f}".format(loss0))
print("initial accuracy: {:.2f}".format(accuracy0))

history = model.fit(train_batches,
                    epochs=initial_epochs,
                    validation_data=validation_batches)

"""# Learning curves

Let's take a look at the learning curves of the training and validation accuracy/loss when using the CNN model as a feature extractor.
"""

def display_training_curves(training, validation, title, subplot):
  ax = plt.subplot(subplot)
  ax.plot(training)
  ax.plot(validation)
  ax.set_title('model '+ title)
  ax.set_ylabel(title)
  ax.set_xlabel('epoch')
  ax.legend(['training', 'validation'])

plt.subplots(figsize=(10,10))
plt.tight_layout()
display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)
display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)
plt.show()
"""----"""

history = model.fit(train_batches,
                    epochs=initial_epochs*2,
                    initial_epoch = initial_epochs,
                    validation_data=validation_batches)

plt.subplots(figsize=(10,10))
plt.tight_layout()
display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)
display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)
plt.show()
